{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "31OpPRdl0Wwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "totalwalk = []\n",
        "c=0\n",
        "\n",
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = random.randint(1, 7)\n",
        "        if dice <= 2:\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice <= 5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + random.randint(1, 7)\n",
        "            c=c+1\n",
        "\n",
        "    print(step)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUBgQlg3gHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAwO8CRk1L6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# \"CREATE RANDOM DATA FOR MULTIPLE LINEAR REGRESSION\"\n",
        "from sklearn.datasets import make_regression\n",
        "from matplotlib import pyplot\n",
        "# generate regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=3, noise=0.3)\n",
        "# plot regression dataset\n",
        "pyplot.scatter(X[:,0]+X[:,1]+X[:,2],y)\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRaep1AA1mIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"CREATE RANDOM DATA FOR LOGISTIC REGRESSION\"\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_blobs\n",
        "from pandas import DataFrame\n",
        "# generate 2d classification dataset\n",
        "X1, y1 = make_blobs(n_samples=100, centers=2, n_features=2)\n",
        "# scatter plot, dots colored by class value\n",
        "df = DataFrame(dict(x=X1[:,0], y=X1[:,1], label=y1))            # scatter plot, dots colored by class value\n",
        "colors = {0:'green', 1:'red'}\n",
        "fig, ax = pyplot.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg4y0PR41qbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"CREATE RANDOM DATA FOR k-MEANS CLUSTERIN \"\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame\n",
        "from sklearn.datasets import make_blobs\n",
        "X2, y2 = make_blobs(n_samples=100, centers=3, n_features=2). # generate 2d classification dataset\n",
        "df = DataFrame(dict(x=X2[:,0], y=X2[:,1], label=y2))         # scatter plot, dots colored by class value\n",
        "colors = {0:'red', 1:'blue', 2:'yellow'}\n",
        "fig, ax = pyplot.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9_qES_g3hzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question 3 - Implement the following algorithms from scratch using numpy only and using the data from Question 1 “for loop” \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MjIbHca3iqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"a. Linear Regression using Gradient Descent\"\n",
        " X1 = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y1 = df.iloc[:,5].values\n",
        "m = 0\n",
        "n = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y = m*X1 + n\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  dv1 = (-2/n) * sum(X1 * (y1 - y))\n",
        "  dv0 = (-2/n) * sum(y1 - y)\n",
        "  m = m - (l*dv1)\n",
        "  n = n - (l*dv0)\n",
        "\n",
        "print(m,n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yd0Zhtd5t-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"\"\"LOGISTIC REGRESSION WITH GRADIENT DECENT\"\"\"\n",
        "\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "a = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,a)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "  a = a - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLo9NUkK7NxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"Linear regression using L1 regularisation\")\n",
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWHVENeR7Rxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"Linear regression using L2 regularisation\"\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raodchQu7eUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"Logistic regression using L1 regularisation\"\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsVDrihu7nry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"Logistic regression using L2 regularisation\"\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhuVi0cx7wpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in data:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7gV0tic5UWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "285c4d82-30c3-46b5-fdff-0ee24db1d2d6"
      },
      "source": [
        "clf = K_Means()\n",
        "clf.fit(X3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.540379178139013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_7YJrmz8AkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce7b4819-ea77-40d1-c432-2d2323710f49"
      },
      "source": [
        "correct = 0\n",
        "for i in range(len(X3)):\n",
        "    predict_me = np.array(X3[i].astype(float))\n",
        "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
        "    prediction = clf.predict(predict_me)\n",
        "    if prediction == y3[i]:\n",
        "        correct += 1\n",
        "print(correct/len(X3))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.33\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}